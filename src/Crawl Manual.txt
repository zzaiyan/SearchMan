作者：乔裕哲 151220086
版本：v1.3
1.3	 修复解析网页数据时可能导致abort()的问题：string.find返回-1
	 用户可以输入MAXFILECOUNT来限定爬取网页数
	 增加根据入度进行直接选择排序的函数
	 在调用爬虫的任何功能之前（sort_pages,crwal,init_website）,先初始化，调用init_global_vars，
	 初始化前先输入MAXFILECOUNT

爬虫部分：1.先输入MAXFILECOUNT，限定爬取的网页数量
	  2.然后调用init_global_vars初始化一些全局变量以供爬虫使用
	  3.将入口链接入队，然后取队首链接，通过套接字获取对应的html代码，并解析出其中的所有链接，加入队列中
	  4.保存数据，分为三部分，html文件夹下保存html代码，text文件夹下保存代码里的中文，供分词和倒排索引使用，
	    url文件夹下保存对应网站链接。
	  5.将队首链接加入已访问网站集合，出队。
	  6.直到队空或爬到限定个数的网页，终止爬虫。

pagerank：1.利用爬虫得到一个链接数组，依次从磁盘中读取对应链接的html文档，并解析出其中的链接，解析方法同爬虫。
	  2.若解析的链接能在数组中找到，则修改对应的网页有向图的邻接矩阵，建立矩阵完毕。
	  3.根据矩阵得到每个网页的入度出度，然后利用pagerank公式计算。
	  
布尔检索：1.用户输入一个字符串，遍历其中的字符数组，将表达式划分为若干个token
	  2.利用栈将中缀表达式转换成后缀表达式
	  3.对每个token的内容，如果该token是操作数，就对其分词，并搜索，搜索结果也保存在token中
	  4.将搜索后的token用栈计算表达式的值，最终得到一个搜索结果